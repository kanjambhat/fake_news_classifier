{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJZLjps0Dwnc",
        "outputId": "a04bcd9f-9e8a-4c61-c8a5-6d159e79f5a9"
      },
      "source": [
        "!pip install ftfy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 32.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 36.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 24.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41935 sha256=82e61964e40cfb35b0a5d1e7b2c86c7166b36cc0f1806d9140b113016186d30f\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjeOUCrrOELJ",
        "outputId": "78a8c4d5-7352-4345-fe9d-90858f3bf816"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywo9UeJ-OMcj"
      },
      "source": [
        "import re #matching regular expression\n",
        "import ftfy #fixes text for you:fixes all the junk characters\n",
        "import nltk#natural language toolkit\n",
        "import itertools #for iterations to matrix\n",
        "import numpy as np #for array\n",
        "import warnings #overcome warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd #read data\n",
        "import pickle as pkl #store tokenizer\n",
        "from pathlib import Path #create json file\n",
        "from nltk import PorterStemmer #for stemming process\n",
        "import matplotlib.pyplot as plt #plot confusion matrix\n",
        "from nltk.corpus import stopwords #for remove stop words\n",
        "from sklearn.model_selection import train_test_split #split data\n",
        "from keras.models import Model, Sequential #adding layers one by one\n",
        "from keras.optimizers import Adam #for optimize the training\n",
        "from keras.preprocessing.text import Tokenizer #to genarate unique number for uniq words\n",
        "from keras.preprocessing.sequence import pad_sequences #for making all the record has same shape\n",
        "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score #for evaluate the model accuracy\n",
        "from keras.layers import Conv1D, Dense, Input, LSTM, Embedding, Dropout, Activation, MaxPooling1D #Layers for build model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIqZXBgsOaYr"
      },
      "source": [
        "max_length=300\n",
        "nb_max_words=100000\n",
        "embedding_dim=10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czKAIvH8OddG"
      },
      "source": [
        "fake_news = '/content/gdrive/MyDrive/Fake_News/Fake.csv'\n",
        "true_news = '/content/gdrive/MyDrive/Fake_News/True.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6sFFrPWOffy"
      },
      "source": [
        "df_fake_news = pd.read_csv(fake_news)\n",
        "df_true_news = pd.read_csv(true_news)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2a0ZTpzTUsk"
      },
      "source": [
        "cList = pkl.load(open('/content/gdrive/MyDrive/Fake_News/cword_dict.pkl','rb'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ5LBhtuTaw3"
      },
      "source": [
        "c_re = re.compile('(%s)' % '|'.join(cList.keys()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snxaObjqTdyf"
      },
      "source": [
        "def expandContractions(text, c_re=c_re):\n",
        "    def replace(match):\n",
        "        return cList[match.group(0)]\n",
        "    return c_re.sub(replace, text)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcvrEMRFThgf"
      },
      "source": [
        "def clean_news(newses):\n",
        "    cleaned_news = []\n",
        "    for news in newses:\n",
        "        news = str(news)\n",
        "        if re.match(\"(\\w+:\\/\\/\\S+)\", news) == None and len(news) > 5:\n",
        "            news = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(\\#[A-Za-z0-9]+)|(<Emoji:.*>)|(pic\\.twitter\\.com\\/.*)\", \" \", news).split())\n",
        "            news = ftfy.fix_text(news)\n",
        "            news = expandContractions(news)\n",
        "            news = ' '.join(re.sub(\"([^0-9A-Za-z \\t])\", \" \", news).split())\n",
        "            stop_words = stopwords.words('english')\n",
        "            word_tokens = nltk.word_tokenize(news) \n",
        "            filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "            news = ' '.join(filtered_sentence)\n",
        "            news = PorterStemmer().stem(news)\n",
        "            cleaned_news.append(news)\n",
        "    return cleaned_news"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "560dudIpTjh0"
      },
      "source": [
        "arr_fake_news = [x for x in df_fake_news['text']]\n",
        "arr_true_news = [x for x in df_true_news['text']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVKExzleTmDw",
        "outputId": "0c2c1361-ed40-42df-f7bf-64cf116f7a3d"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEetV5ahTn8L"
      },
      "source": [
        "cleaned_fake_news = clean_news(arr_fake_news)\n",
        "cleaned_true_news = clean_news(arr_true_news)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "uZE4HPnT5uEs",
        "outputId": "fcffb402-bae8-4cc9-a8b3-334a60aeb098"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c1a774c60e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_fake_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4FM9NY4TqE8"
      },
      "source": [
        "from keras.preprocessing.text import one_hot"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXxl-LELUlVn"
      },
      "source": [
        "files = open('/content/gdrive/MyDrive/Fake_News/tokenizer.pkl','wb')\n",
        "pkl.dump(tokenizer,files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu4L5PN1Uq0V"
      },
      "source": [
        "# sequences_fake = tokenizer.texts_to_sequences(cleaned_fake_news)\n",
        "# sequences_true = tokenizer.texts_to_sequences(cleaned_true_news)\n",
        "\n",
        "sequences_fake=[one_hot(words,nb_max_words) for words in cleaned_fake_news]\n",
        "sequences_true=[one_hot(words,nb_max_words) for words in cleaned_true_news]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eICpEvVU8NlE",
        "outputId": "4c014996-cbdd-45be-beae-9269758a2d11"
      },
      "source": [
        "print(sequences_fake)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AS6WeopUwIR",
        "outputId": "b9f59737-493e-4d02-a9e3-d8b20acdaab2"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 104287 unique tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EljCKebnVB60",
        "outputId": "91afffa6-75c0-4579-d282-27b63073d8af"
      },
      "source": [
        "data_f = pad_sequences(sequences_fake, padding='pre', maxlen=max_length)\n",
        "data_t = pad_sequences(sequences_true,padding='pre', maxlen=max_length)\n",
        "print('Shape of data_fake tensor:', data_f.shape)\n",
        "print('Shape of data_true tensor:', data_t.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data_fake tensor: (22755, 300)\n",
            "Shape of data_true tensor: (21416, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX7ZpECc4yub",
        "outputId": "e0ea13c5-7c30-4c70-8a8c-48ab3377ae15"
      },
      "source": [
        "print(data_f)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0 ... 61409  1086 65542]\n",
            " [    0     0     0 ... 69772 32921 64348]\n",
            " [    0     0     0 ... 87513 20237 76067]\n",
            " ...\n",
            " [95769 90907  6583 ... 59446 12954 73009]\n",
            " [    0     0     0 ... 45038 85587 60557]\n",
            " [43080 43351  5599 ... 59446 65366 73009]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEcCfHlw4y3s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXOZGfMfVE2b"
      },
      "source": [
        "data = np.concatenate((data_f, data_t))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im7Xlqj95ld4",
        "outputId": "37a284c6-0cc1-4072-e44e-a03f58a7c3c8"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0 ... 61409  1086 65542]\n",
            " [    0     0     0 ... 69772 32921 64348]\n",
            " [    0     0     0 ... 87513 20237 76067]\n",
            " ...\n",
            " [    0     0     0 ... 62727 94022 43080]\n",
            " [    0     0     0 ... 10565 74745 21809]\n",
            " [    0     0     0 ...  3237  9668 78577]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXVB3TTzVIfW",
        "outputId": "4127f170-6e2e-4275-8edb-78033d0506a3"
      },
      "source": [
        "labels_f = np.ones(data_f.shape[0])\n",
        "labels_t = np.zeros(data_t.shape[0])\n",
        "print(labels_f.shape, labels_t.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22755,) (21416,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFN6ni3VLaH"
      },
      "source": [
        "labels = np.concatenate((labels_f, labels_t))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QIA9RTpVNaU"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.2, random_state=42)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIWO1XuXVP6O"
      },
      "source": [
        "from keras.layers import Flatten"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI9Th-qCVSR-",
        "outputId": "b5f9cae2-e4cd-4a51-afd6-2fb3b972ac1a"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(nb_max_words,embedding_dim,input_length=max_length))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Conv1D(filters=16,kernel_size=3,padding='valid',activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=32,kernel_size=3,padding='valid',activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 10)           1000000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 300, 10)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 298, 16)           496       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 149, 16)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 149, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 147, 32)           1568      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 73, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 73, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2336)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                149568    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,151,697\n",
            "Trainable params: 1,151,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn58B1HVVWqH",
        "outputId": "c8733992-6b01-4ed7-9f27-e4848add8a30"
      },
      "source": [
        "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=10,batch_size=64)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "553/553 [==============================] - 33s 31ms/step - loss: 0.6844 - accuracy: 0.5315 - val_loss: 0.7086 - val_accuracy: 0.6544\n",
            "Epoch 2/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.3425 - accuracy: 0.8595 - val_loss: 0.5314 - val_accuracy: 0.7540\n",
            "Epoch 3/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.1887 - accuracy: 0.9302 - val_loss: 0.4516 - val_accuracy: 0.7978\n",
            "Epoch 4/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.1580 - accuracy: 0.9424 - val_loss: 0.4125 - val_accuracy: 0.8114\n",
            "Epoch 5/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.1338 - accuracy: 0.9513 - val_loss: 0.2977 - val_accuracy: 0.8645\n",
            "Epoch 6/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.1148 - accuracy: 0.9574 - val_loss: 0.2528 - val_accuracy: 0.8918\n",
            "Epoch 7/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.1096 - accuracy: 0.9620 - val_loss: 0.1961 - val_accuracy: 0.9202\n",
            "Epoch 8/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.0992 - accuracy: 0.9646 - val_loss: 0.2316 - val_accuracy: 0.9035\n",
            "Epoch 9/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.0970 - accuracy: 0.9672 - val_loss: 0.1854 - val_accuracy: 0.9278\n",
            "Epoch 10/10\n",
            "553/553 [==============================] - 16s 29ms/step - loss: 0.0908 - accuracy: 0.9683 - val_loss: 0.1957 - val_accuracy: 0.9217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f322fa02310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw_odSgYVblr"
      },
      "source": [
        "model.save('CNN_model.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghzwoQikZ_yf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}